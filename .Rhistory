cosDist_mds %>% arrange(clusters, desc(n)) %>% filter(n > 5)
# get PAM clusters
pams <- c()
for(i in 1:15) {
cur_pam <- pam(cosDist_mds, k = i)
pams[i] <- cur_pam$silinfo$avg.width
}
plot(1:15, pams)
plot(1:15, pams, type = "b")
library(tidyverse)
library(wordVectors)
library(vroom)
library(pbapply)
library(readxl)
library(ggrepel)
library(cluster)
#con <-url("https://osf.io/download/wxe2r/")
# model <- readRDS(con)
model <- readRDS("/Users/stefanhartmann/sciebo/Projekte/snowclones/word2vec/model.Rds")
# model = train_word2vec("cookbooks.txt","cookbook_vectors.bin",vectors=100,threads=4,window=3,iter=2,negative_samples=2)
# str(model)
# check results
model %>% closest_to("fish")
model %>% closest_to("woman")
# cosine distances
# Inspect the similarity of several academic disciplines by hand.
subjects = model[[c("history","literature","biology","math","stats"),average=FALSE]]
similarities = cosineSimilarity(subjects,subjects)
# all lemmas in arch-
# read nouns
arch_nouns <- read_xlsx("COW16 nouns cleaned.xlsx")
# read adj
arch_adj   <- read_xlsx("COW16 adjectives cleaned.xlsx")
# export distances for all words in arch ------
# remove false hits
arch_adj <- filter(arch_adj, Keep=="y")
arch_nouns <- filter(arch_nouns, Keep=="y")
# get bases
arch_adj$Base_Lemma <- gsub("^arch-?", "", arch_adj$Token)
arch_nouns$Base_Lemma <- gsub("^arch-?", "", arch_nouns$Token)
# get lemmas
lemmas <- sort(unique(c(arch_adj$Base_Lemma, arch_nouns$Base_Lemma)))
# get Cosine distance
cosDist_mds <- cosineDist(model[[tolower(lemmas), average = FALSE]], model[[tolower(lemmas), average = FALSE]]) %>% cmdscale()
# as df
cosDist_mds <- cosDist_mds %>% as.data.frame() %>% rownames_to_column()
colnames(cosDist_mds)[1] <- "lemma"
# add frequency information
freqs <- rbind(arch_adj, arch_nouns) %>% select(Base_Lemma, Frequency) %>%
group_by(Base_Lemma) %>%
summarise(
n = sum(Frequency)
) %>% setNames(c("lemma", "n"))
# freqs <- c(arch_adj$Base_Lemma, arch_nouns$Base_Lemma) %>% table %>% sort %>% as_tibble() %>% setNames(c("lemma", "n"))
cosDist_mds <- left_join(cosDist_mds, freqs) %>% replace_na(list(n = 0))
cosDist_mds$logFreq <- log1p(cosDist_mds$n)
# get PAM clusters
pams <- c()
for(i in 1:15) {
cur_pam <- pam(cosDist_mds, k = i)
pams[i] <- cur_pam$silinfo$avg.width
}
plot(1:15, pams, type = "b") # line elbows at ~ 3
pam_clusters <- pam(cosDist_mds, k = 3)
cosDist_mds$clusters <- factor(pam_clusters$clustering)
# add a column that contains the frequencies but sets
# all frequemcies
# get plot
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = clusters)) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_viridis_d(begin = .1, end = .9)  +
guides(col = "none")
#ggsave("archdistances.png")
ggsave("archdistances.png")
?kmeans
# get k-means clusters
kmeans(cosDist_mds, 4, nstart = 25)
library(tidyverse)
library(wordVectors)
library(vroom)
library(pbapply)
library(readxl)
library(ggrepel)
library(cluster)
#con <-url("https://osf.io/download/wxe2r/")
# model <- readRDS(con)
model <- readRDS("/Users/stefanhartmann/sciebo/Projekte/snowclones/word2vec/model.Rds")
# model = train_word2vec("cookbooks.txt","cookbook_vectors.bin",vectors=100,threads=4,window=3,iter=2,negative_samples=2)
# str(model)
# check results
model %>% closest_to("fish")
model %>% closest_to("woman")
# cosine distances
# Inspect the similarity of several academic disciplines by hand.
subjects = model[[c("history","literature","biology","math","stats"),average=FALSE]]
similarities = cosineSimilarity(subjects,subjects)
# all lemmas in arch-
# read nouns
arch_nouns <- read_xlsx("COW16 nouns cleaned.xlsx")
# read adj
arch_adj   <- read_xlsx("COW16 adjectives cleaned.xlsx")
# export distances for all words in arch ------
# remove false hits
arch_adj <- filter(arch_adj, Keep=="y")
arch_nouns <- filter(arch_nouns, Keep=="y")
# get bases
arch_adj$Base_Lemma <- gsub("^arch-?", "", arch_adj$Token)
arch_nouns$Base_Lemma <- gsub("^arch-?", "", arch_nouns$Token)
# get lemmas
lemmas <- sort(unique(c(arch_adj$Base_Lemma, arch_nouns$Base_Lemma)))
# get Cosine distance
cosDist_mds <- cosineDist(model[[tolower(lemmas), average = FALSE]], model[[tolower(lemmas), average = FALSE]]) %>% cmdscale()
# get k-means clusters
kmeans(cosDist_mds, 4, nstart = 25)
# get k-means clusters
plot(1:10, sapply(1:10, function(x) kmeans(cosDist_mds, x, nstart = 25)$tot.withinss))
# get k-means clusters
plot(1:10, sapply(1:10, function(x) kmeans(cosDist_mds, x, nstart = 25)$tot.withinss), type = "b", ylab = "WCSS")
k_means_clusters <- kmeans(cosDist_mds, 3, nstart = 25)
k_means_clusters
k_means_clusters$cluster
# as df
cosDist_mds <- cosDist_mds %>% as.data.frame() %>% rownames_to_column()
colnames(cosDist_mds)[1] <- "lemma"
# add frequency information
freqs <- rbind(arch_adj, arch_nouns) %>% select(Base_Lemma, Frequency) %>%
group_by(Base_Lemma) %>%
summarise(
n = sum(Frequency)
) %>% setNames(c("lemma", "n"))
# freqs <- c(arch_adj$Base_Lemma, arch_nouns$Base_Lemma) %>% table %>% sort %>% as_tibble() %>% setNames(c("lemma", "n"))
cosDist_mds <- left_join(cosDist_mds, freqs) %>% replace_na(list(n = 0))
cosDist_mds$logFreq <- log1p(cosDist_mds$n)
# get PAM clusters
pams <- c()
for(i in 1:15) {
cur_pam <- pam(cosDist_mds, k = i)
pams[i] <- cur_pam$silinfo$avg.width
}
plot(1:15, pams, type = "b") # line elbows at ~ 3
pam_clusters <- pam(cosDist_mds, k = 3)
cosDist_mds$clusters <- factor(pam_clusters$clustering)
# add k-means clusters
k_means_clusters
# add k-means clusters
k_means_clusters$cluster
# add k-means clusters
as.numeric(k_means_clusters$cluster)
# add k-means clusters
as.factor(as.numeric(k_means_clusters$cluster))
# add k-means clusters
cosDist_mds$kcluster <- as.factor(as.numeric(k_means_clusters$cluster))
# get plot
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kluster)) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_viridis_d(begin = .1, end = .9)  +
guides(col = "none")
# get plot
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kcluster)) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_viridis_d(begin = .1, end = .9)  +
guides(col = "none")
k_means_clusters
# get plot
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = clusters)) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_viridis_d(begin = .1, end = .9)  +
guides(col = "none")
ggsave("archdistances.png")
# or with k-means clusters instead
set.seed(1705)
# or with k-means clusters instead
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kcluster)) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_viridis_d(begin = .1, end = .9)  +
guides(col = "none")
ggsave("archdistances.png")
# get plot
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = clusters)) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_viridis_d(begin = .1, end = .9)  +
guides(col = "none")
ggsave("archdistances_pam.png")
# or with k-means clusters instead
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kcluster)) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_viridis_d(begin = .1, end = .9)  +
guides(col = "none")
ggsave("archdistances_k_means.png")
plogis(2)
View(cosDist_mds)
15/40
library(tidyverse)
library(wordVectors)
library(vroom)
library(pbapply)
library(readxl)
library(ggrepel)
library(cluster)
#con <-url("https://osf.io/download/wxe2r/")
# model <- readRDS(con)
model <- readRDS("/Users/stefanhartmann/sciebo/Projekte/snowclones/word2vec/model.Rds")
# check results
model %>% closest_to("fish")
model %>% closest_to("woman")
# cosine distances
# Inspect the similarity of several academic disciplines by hand.
subjects = model[[c("history","literature","biology","math","stats"),average=FALSE]]
similarities = cosineSimilarity(subjects,subjects)
# read nouns
arch_nouns <- read_xlsx("COW16 nouns cleaned.xlsx")
# read adj
arch_adj   <- read_xlsx("COW16 adjectives cleaned.xlsx")
# remove false hits
arch_adj <- filter(arch_adj, Keep=="y")
arch_nouns <- filter(arch_nouns, Keep=="y")
# get bases
arch_adj$Base_Lemma <- gsub("^arch-?", "", arch_adj$Token)
arch_nouns$Base_Lemma <- gsub("^arch-?", "", arch_nouns$Token)
# make sheet for annotating lexemes / correcting lemmas
rbind(arch_adj, arch_nouns)
# make sheet for annotating lexemes / correcting lemmas
rbind(arch_adj, arch_nouns) %>% writexl::write_xlsx("arch_adj_n.xlsx")
# make sheet for annotating lexemes / correcting lemmas
rbind(mutate(arch_adj, pos = "ADJ"), mutate(arch_nouns, pos = "N")) %>% writexl::write_xlsx("arch_adj_n.xlsx")
# read in again
arch <- read_xlsx("arch_adj_n.xlsx")
# get lemmas
sort(unique(arch$Base_Lemma))
# get lemmas
lemmas <- sort(unique(arch$Base_Lemma))
# get Cosine distance
cosDist_mds <- cosineDist(model[[tolower(lemmas), average = FALSE]], model[[tolower(lemmas), average = FALSE]]) %>% cmdscale()
# get k-means clusters
plot(1:10, sapply(1:10, function(x) kmeans(cosDist_mds, x, nstart = 25)$tot.withinss), type = "b", ylab = "WCSS")
k_means_clusters <- kmeans(cosDist_mds, 3, nstart = 25)
# as df
cosDist_mds <- cosDist_mds %>% as.data.frame() %>% rownames_to_column()
colnames(cosDist_mds)[1] <- "lemma"
# add frequency information
freqs <- rbind(arch_adj, arch_nouns) %>% select(Base_Lemma, Frequency) %>%
group_by(Base_Lemma) %>%
summarise(
n = sum(Frequency)
) %>% setNames(c("lemma", "n"))
# freqs <- c(arch_adj$Base_Lemma, arch_nouns$Base_Lemma) %>% table %>% sort %>% as_tibble() %>% setNames(c("lemma", "n"))
cosDist_mds <- left_join(cosDist_mds, freqs) %>% replace_na(list(n = 0))
cosDist_mds$logFreq <- log1p(cosDist_mds$n)
# get PAM clusters
pams <- c()
for(i in 1:15) {
cur_pam <- pam(cosDist_mds, k = i)
pams[i] <- cur_pam$silinfo$avg.width
}
plot(1:15, pams, type = "b") # line elbows at ~ 3
pam_clusters <- pam(cosDist_mds, k = 3)
cosDist_mds$clusters <- factor(pam_clusters$clustering)
# add k-means clusters
cosDist_mds$kcluster <- as.factor(as.numeric(k_means_clusters$cluster))
# get plot
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = clusters)) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_viridis_d(begin = .1, end = .9)  +
guides(col = "none")
ggsave("archdistances_pam.png")
# or with k-means clusters instead
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kcluster)) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_viridis_d(begin = .1, end = .9)  +
guides(col = "none")
ggsave("archdistances_k_means.png")
ggsave("archdistances_k_means.png", width = 7, height = 5)
# or with k-means clusters instead
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kcluster)) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_viridis_d(begin = .3, end = .8)  +
guides(col = "none")
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kcluster)) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_grey() +
#scale_color_viridis_d(begin = .3, end = .8)  +
guides(col = "none")
# or with k-means clusters instead
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kcluster)) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_grey() +
#scale_color_viridis_d(begin = .3, end = .8)  +
guides(col = "none")
# or with k-means clusters instead
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kcluster)) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_grey(start = .2, end = .8) +
#scale_color_viridis_d(begin = .3, end = .8)  +
guides(col = "none")
# or with k-means clusters instead
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kcluster)) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_grey(start = .3, end = .8) +
#scale_color_viridis_d(begin = .3, end = .8)  +
guides(col = "none")
# or with k-means clusters instead
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kcluster)) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_grey(start = .1, end = .6) +
#scale_color_viridis_d(begin = .3, end = .8)  +
guides(col = "none")
ggsave("archdistances_k_means.png", width = 7, height = 5)
# or with k-means clusters instead
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kcluster)) +
stat_ellipse(aes(group = kcluster, fill = as.factor(kcluster)),
geom = "polygon", alpha = 0.2, color = NA) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_grey(start = .1, end = .6) +
#scale_color_viridis_d(begin = .3, end = .8)  +
guides(col = "none")
# or with k-means clusters instead
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kcluster)) +
stat_ellipse(aes(group = kcluster, fill = as.factor(kcluster)),
geom = "polygon", alpha = 0.2) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_grey(start = .1, end = .6) +
#scale_color_viridis_d(begin = .3, end = .8)  +
guides(col = "none")
# or with k-means clusters instead
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kcluster)) +
stat_ellipse(aes(group = kcluster, fill = as.factor(kcluster)),
geom = "polygon", alpha = 0.2, color = NA) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_grey(start = .1, end = .6) +
#scale_color_viridis_d(begin = .3, end = .8)  +
guides(col = "none")
# or with k-means clusters instead
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kcluster)) +
stat_ellipse(aes(group = kcluster, fill = kcluster),
geom = "polygon", alpha = 0.2, color = NA) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_grey(start = .1, end = .6) +
#scale_color_viridis_d(begin = .3, end = .8)  +
guides(col = "none")
# or with k-means clusters instead
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kcluster)) +
stat_ellipse(aes(group = kcluster, fill = kcluster, group = 1),
geom = "polygon", alpha = 0.2, color = NA) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_grey(start = .1, end = .6) +
#scale_color_viridis_d(begin = .3, end = .8)  +
guides(col = "none")
# or with k-means clusters instead
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kcluster)) +
stat_ellipse(aes(group = as.factor(kcluster), fill = as.factor(kcluster)),
geom = "polygon", alpha = 0.2, color = NA) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_grey(start = .1, end = .6) +
#scale_color_viridis_d(begin = .3, end = .8)  +
guides(col = "none")
# or with k-means clusters instead
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kcluster)) +
stat_ellipse(aes(group = as.factor(kcluster), fill = as.factor(kcluster)),
geom = "polygon", alpha = 0.2, color = NA) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_grey(start = .1, end = .6) +
#scale_color_viridis_d(begin = .3, end = .8)  +
guides(col = "none", fill = "none")
ggsave("archdistances_k_means.png", width = 7, height = 5)
# or with k-means clusters instead
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma, col = kcluster)) +
stat_ellipse(aes(group = as.factor(kcluster), fill = as.factor(kcluster)),
geom = "polygon", alpha = 0.1, color = NA) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_grey(start = .1, end = .6) +
#scale_color_viridis_d(begin = .3, end = .8)  +
guides(col = "none", fill = "none")
ggsave("archdistances_k_means.png", width = 7, height = 5)
# or with k-means clusters instead
set.seed(1705)
cosDist_mds %>% filter(logFreq>2) %>% ggplot(aes(x = V1, y = V2,
size = n*5, label = lemma)) +
stat_ellipse(aes(group = as.factor(kcluster), fill = as.factor(kcluster)),
geom = "polygon", alpha = 0.1, color = NA) +
geom_text_repel(max.overlaps = 25) + theme_bw() + guides(size = 'none') +
scale_color_grey(start = .1, end = .6) +
#scale_color_viridis_d(begin = .3, end = .8)  +
guides(col = "none", fill = "none")
ggsave("archdistances_k_means.png", width = 7, height = 5)
ggsave("archdistances_k_means.png", width = 7, height = 5, dpi = 300)
ggsave("archdistances_k_means.png", width = 7, height = 5, dpi = 600)
rm(list=ls())
# Chunk 1
library(tidyverse)
library(wordVectors)
library(vroom)
library(pbapply)
library(readxl)
library(ggrepel)
library(cluster)
# Chunk 2
# read nouns
arch_nouns <- read_xlsx("COW16 nouns cleaned.xlsx")
# read adj
arch_adj   <- read_xlsx("COW16 adjectives cleaned.xlsx")
# Chunk 3
# remove false hits
arch_adj <- filter(arch_adj, Keep=="y")
arch_nouns <- filter(arch_nouns, Keep=="y")
# get bases
arch_adj$Base_Lemma <- gsub("^arch-?", "", arch_adj$Token)
arch_nouns$Base_Lemma <- gsub("^arch-?", "", arch_nouns$Token)
# make sheet for annotating lexemes / correcting lemmas
# rbind(mutate(arch_adj, pos = "ADJ"), mutate(arch_nouns, pos = "N")) %>% writexl::write_xlsx("arch_adj_n.xlsx")
# read in again
arch <- read_xlsx("arch_adj_n.xlsx")
# Chunk 1
library(tidyverse)
library(wordVectors)
library(vroom)
library(pbapply)
library(readxl)
library(ggrepel)
library(cluster)
# Chunk 2
# read nouns
arch_nouns <- read_xlsx("COW16 nouns cleaned.xlsx")
# read adj
arch_adj   <- read_xlsx("COW16 adjectives cleaned.xlsx")
# Chunk 3
# remove false hits
arch_adj <- filter(arch_adj, Keep=="y")
arch_nouns <- filter(arch_nouns, Keep=="y")
# get bases
arch_adj$Base_Lemma <- gsub("^arch-?", "", arch_adj$Token)
arch_nouns$Base_Lemma <- gsub("^arch-?", "", arch_nouns$Token)
# make sheet for annotating lexemes / correcting lemmas
# rbind(mutate(arch_adj, pos = "ADJ"), mutate(arch_nouns, pos = "N")) %>% writexl::write_xlsx("arch_adj_n.xlsx")
# read in again
arch <- read_xlsx("arch_adj_n.xlsx")
# Chunk 4
model <- readRDS("/Users/stefanhartmann/sciebo/Projekte/snowclones/word2vec/model.Rds")
# Chunk 1
library(tidyverse)
library(wordVectors)
library(vroom)
library(pbapply)
library(readxl)
library(ggrepel)
library(cluster)
# Chunk 2
# read nouns
arch_nouns <- read_xlsx("COW16 nouns cleaned.xlsx")
# read adj
arch_adj   <- read_xlsx("COW16 adjectives cleaned.xlsx")
# Chunk 3
# remove false hits
arch_adj <- filter(arch_adj, Keep=="y")
arch_nouns <- filter(arch_nouns, Keep=="y")
# get bases
arch_adj$Base_Lemma <- gsub("^arch-?", "", arch_adj$Token)
arch_nouns$Base_Lemma <- gsub("^arch-?", "", arch_nouns$Token)
# make sheet for annotating lexemes / correcting lemmas
# rbind(mutate(arch_adj, pos = "ADJ"), mutate(arch_nouns, pos = "N")) %>% writexl::write_xlsx("arch_adj_n.xlsx")
# read in again
arch <- read_xlsx("arch_adj_n.xlsx")
# Chunk 4
#| message: false
#| warning: false
#| include: false
model <- readRDS("/Users/stefanhartmann/sciebo/Projekte/snowclones/word2vec/model.Rds")
model
